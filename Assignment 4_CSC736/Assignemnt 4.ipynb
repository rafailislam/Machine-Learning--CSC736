{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Feb 25 15:31:38 2020\n",
    "\n",
    "@author: rit1115\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_vector=[[0.9,0.1,0.1,0.1],[0.1,0.9,0.1,0.1],[0.1,0.1,0.9,0.1],[0.1,0.1,0.1,0.9]]\n",
    "# learning rate\n",
    "n = 0.0001\n",
    "a = 0.4\n",
    "wji = []\n",
    "wkj =[]\n",
    "delta_j=[]\n",
    "delta_k=[]\n",
    "y_k=[]\n",
    "bias_j=[]\n",
    "bias_k=[]\n",
    "\n",
    "\n",
    "def read_traing_data():\n",
    "    train=[]\n",
    "    train_output=[]\n",
    "    with open('optdigits-3.tra') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            rows=[]\n",
    "            for i in range(64):\n",
    "                rows.append( (int(row[i]))/16)\n",
    "            #print(len(rows))\n",
    "            output = int(row[64])\n",
    "            #print(output)\n",
    "            train_output.append(output_vector[output])\n",
    "            train.append(rows)\n",
    "    return train,train_output\n",
    "\n",
    "def read_testing_data():\n",
    "    test=[]\n",
    "    test_output=[]\n",
    "    with open('optdigits-3.tes') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            #print(len(row))\n",
    "            rows=[]\n",
    "            \n",
    "            for i in range(64):\n",
    "                rows.append( (int(row[i]))/16)\n",
    "            #print(len(rows))\n",
    "            output = int(row[64])\n",
    "            #print(output)\n",
    "            test_output.append(output_vector[output])\n",
    "            test.append(rows)\n",
    "    return test, test_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(no_hidden_node):\n",
    "    ''' this function takes the number of nodes in hidden layer and return weight both for input-hidded and hidden-output layer.\n",
    "    it also returns bias and delta\n",
    "    '''\n",
    "    global wji \n",
    "    global wkj\n",
    "    global delta_j \n",
    "    global delta_k \n",
    "    global y_k \n",
    "    global bias_j \n",
    "    global bias_k \n",
    "    \n",
    "    for _ in range(64*no_hidden_node):\n",
    "        wji.append(round(np.random.uniform(-1,1),3))\n",
    "   \n",
    "    wji= np.reshape(wji,(64,no_hidden_node)).tolist()\n",
    "    \n",
    "    wkj=[round(np.random.uniform(-1,1),3) for _ in range(no_hidden_node*4)] \n",
    "    wkj= np.reshape(wkj,(no_hidden_node,4)).tolist()\n",
    "   \n",
    "    \n",
    "    delta_j = [0.0]*no_hidden_node\n",
    "    bias_j  = [round(np.random.uniform(-1,1),3) for _ in range(no_hidden_node)] \n",
    "    delta_k = [0.0]*4\n",
    "    bias_k = [round(np.random.uniform(-1,1),3) for _ in range(4)] \n",
    "    y_k = [0.0]*4\n",
    "    \n",
    "    #print(\"wkj\",wkj[0])\n",
    "    return wji,wkj,delta_j,delta_k,y_k,bias_j,bias_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def activation(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def input_hidden_layer(inputs):\n",
    "    y_j = []\n",
    "    #print(len(inputs))\n",
    "    \n",
    "    for j in range(5):\n",
    "        summ = 0\n",
    "        for i in range(64):\n",
    "            summ += inputs[i]*wji[i][j]\n",
    "        summ = summ + bias_j[j]   \n",
    "        y_j.append(activation(summ))     \n",
    "    #print(len(y_j))\n",
    "    \n",
    "    return y_j\n",
    "\n",
    "def hidden_output_layer(y_j):\n",
    "    y_k=[]\n",
    "    #print(y_j)\n",
    "    for i in range(4):\n",
    "        summ = 0\n",
    "        for j in range(5):\n",
    "            summ += y_j[j]*wkj[j][i]\n",
    "        summ = summ + bias_k[i]    \n",
    "        y_k.append(activation(summ))\n",
    "    #print(y_k)\n",
    "    #print(wkj[0])\n",
    "    return y_k\n",
    "def feed_forward(inputs):\n",
    "    y_j = input_hidden_layer(inputs)\n",
    "    y_k = hidden_output_layer(y_j)\n",
    "    return y_j,y_k\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def back_propagate(inputs,desired_outputs, y_j, y_k):\n",
    "    \n",
    "    #print(desired_outputs)\n",
    "    #print(y_k)\n",
    "    \n",
    "    # error in output layer\n",
    "    for i in range(len(desired_outputs)):\n",
    "        delta_k[i] = (a * y_k[i] * (1 - y_k[i]) * (desired_outputs[i] - y_k[i]))\n",
    "    #print(delta_k)\n",
    "    # error in hidden layer\n",
    "    for i in range(len(y_j)):\n",
    "        sum=0\n",
    "        for j in range(len(delta_k)):\n",
    "            sum += delta_k[j] * wkj[i][j]\n",
    "        delta_j[i] = a*y_j[i]*(1-y_j[i])*sum\n",
    "    \n",
    "    #print(delta_j)\n",
    "    \n",
    "    \n",
    "    #print(\"In b\\n\",wkj)\n",
    "    # update hidden-output layer's weights\n",
    "    for j in range(5):\n",
    "        for k in range(4):\n",
    "            wkj[j][k] = wkj[j][k] + n*delta_k[k]*y_j[j]\n",
    "    #print(\"in a\\n\",wkj)\n",
    "    \n",
    "    # update bias of output layer\n",
    "    for k in range(4):\n",
    "        bias_k[k] += n*bias_k[k]*delta_k[k]\n",
    "    #print(\"\\n\",wji)    \n",
    "    # update input-hidden layer's weights\n",
    "    for i in range(64):\n",
    "        for j in range(5):\n",
    "            wji[i][j] = wji[i][j]+ n * delta_j[j]*inputs[i]\n",
    "    #print(\"\\n\\n\",wji)\n",
    "    # update bias of output layer\n",
    "    for j in range(5):\n",
    "        bias_j[j] += n*bias_j[j]*delta_j[j]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_train(train_input_set,desired_outputs):\n",
    "    # train single data set at a time\n",
    "    #print(\"before train\\n\",wkj)\n",
    "    \n",
    "    for i in range(len(train_input_set)):\n",
    "        y_j,y_k = feed_forward(train_input_set[i])\n",
    "        #break\n",
    "        \n",
    "        back_propagate(train_input_set[i], desired_outputs[i], y_j, y_k)\n",
    "        \n",
    "    #print(\"after train\\n\",wkj)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "def mse_calculation(inputs,actual_output):\n",
    "    predicted_output=[]\n",
    "    for i in range(len(inputs)):\n",
    "        y_j,y_k = feed_forward(inputs[i])\n",
    "        predicted_output.append(y_k)\n",
    "    \n",
    "    sum_square= 0\n",
    "    for i in range(len(predicted_output)):\n",
    "        for j in range(4):\n",
    "            sum_square += (actual_output[i][j] - predicted_output[i][j])**2\n",
    "    MSE = sum_square / 2\n",
    "    return MSE    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correctness(testing,desired_output):\n",
    "    predicted_output=[]\n",
    "    for i in range(len(testing)):\n",
    "        y_j,y_k = feed_forward(testing[i])\n",
    "        predicted_output.append(y_k)\n",
    "    correct = 0\n",
    "    for i in range(len(predicted_output)):\n",
    "        #print(predicted_output[i])\n",
    "        #print(desired_output[i])\n",
    "        if( desired_output[i].index(max(desired_output[i])) == predicted_output[i].index(max(predicted_output[i]))):\n",
    "            correct += 1\n",
    "    print(\"no of correct\", correct)\n",
    "    print(desired_output[0])\n",
    "    print(predicted_output[0])\n",
    "    percentage = correct/len(predicted_output) *100 \n",
    "    \n",
    "    return percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_traing = []\n",
    "mse_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "   \n",
    "    \n",
    "    # no of nodes in hidden layer\n",
    "    no_hiddenlayer_node = 5\n",
    "    \n",
    "    # Reading training data from optdigits-3.tra and normalized it\n",
    "    train, train_output = read_traing_data()\n",
    "    \n",
    "    # Reading testing data from optdigits-3.tra and normalized it\n",
    "    test, test_output = read_testing_data()\n",
    "    \n",
    "    # spliting traning data into 80% for training and 20% for validation\n",
    "    \n",
    "    train_input_set,validation_input_set, tarin_output_set,  validation_output_set = train_test_split(\n",
    "        test, test_output, test_size=0.20, random_state=32)\n",
    "    \n",
    "    initialization(no_hiddenlayer_node)\n",
    "    \n",
    "    temp=99999999\n",
    "    \n",
    "    epoch = 1\n",
    "    while(epoch<5000):\n",
    "        plt.clf()\n",
    "        \n",
    "        fcn_train(train_input_set,tarin_output_set)\n",
    "        if(epoch%10==0):\n",
    "            #correct_classification = correctness(test,test_output)\n",
    "            #print(\"Correct Cllasificaoin : \",correct_classification,\" %\")\n",
    "\n",
    "            mse_t =mse_calculation(train_input_set,tarin_output_set)\n",
    "            mse_v = mse_calculation(validation_input_set,validation_output_set)\n",
    "            \n",
    "            mse_traing.append( mse_t) \n",
    "            mse_validation.append(mse_v)\n",
    "            if(temp<mse_v):\n",
    "                break\n",
    "            temp = mse_v\n",
    "            \n",
    "            x_axis.append(epoch)\n",
    "            plt.plot(x_axis, mse_traing, label = 'Training Data Set' )\n",
    "            plt.plot(x_axis, mse_validation, label = 'Validation Data Set' )\n",
    "            plt.xlabel( \"Number of epochs\" )\n",
    "            plt.ylabel( \"Mean Square Error\" )\n",
    "            plt.title( \"Mean Square Error vs Epochs\" )\n",
    "            plt.draw( )\n",
    "            plt.pause( 0.00000001 )\n",
    "        \n",
    "        epoch += 1\n",
    "        \n",
    "        \n",
    "        if epoch % 800 ==0:\n",
    "            n = n + n * 0.8\n",
    "            print(\"epoch: \", epoch)\n",
    "    #end of while\n",
    "    df = pd.DataFrame({\n",
    "        \"Traing\": mse_traing,\n",
    "        \"Validation \": mse_validation \n",
    "    })\n",
    "    ax = df.plot()\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('error')\n",
    "    # calculate accuracy with testing data set\n",
    "    correct_classification = correctness(test,test_output) # even same train set doesnot work well\n",
    "    print(\"Correct Cllasificaoin : %.2f %%\"%(correct_classification))\n",
    "    input ( \"press [enter] to exit\" )\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "        \"Traing\": mse_traing,\n",
    "        \"Validation \": mse_validation \n",
    "    })\n",
    "ax = df.plot()\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
